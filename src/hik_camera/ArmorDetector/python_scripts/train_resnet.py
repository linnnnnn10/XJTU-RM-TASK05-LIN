import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
import cv2
import os
import numpy as np
from sklearn.metrics import accuracy_score
from tqdm import tqdm

class DigitDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        # å¢åŠ è´Ÿæ ·æœ¬ç±»åˆ«ï¼ˆç¬¬6ç±»ï¼‰
        self.classes = ['1', '2', '3', '4', '5', 'negative']
        self.samples = []
        
        for class_idx, class_name in enumerate(self.classes):
            class_dir = os.path.join(data_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"è­¦å‘Š: ç±»åˆ«ç›®å½• {class_dir} ä¸å­˜åœ¨")
                continue
                
            for img_name in os.listdir(class_dir):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.samples.append({
                        'image_path': os.path.join(class_dir, img_name),
                        'label': class_idx
                    })
        
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: æ€»æ ·æœ¬æ•° {len(self.samples)}")
        for i, class_name in enumerate(self.classes):
            class_count = sum(1 for sample in self.samples if sample['label'] == i)
            print(f"  {class_name}: {class_count} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        image = cv2.imread(sample['image_path'])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        if self.transform:
            image = self.transform(image)
            
        return image, sample['label']

def train_model():
    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # ğŸ“ğŸ“ æ•°æ®é›†å¯¼å…¥å…¥å£ï¼šè®¾ç½®æ•°æ®é›†è·¯å¾„
    data_dir = "/home/linnnnnn/ArmorDetector/data/dataset"  # ä¿®æ”¹ä¸ºå®é™…æ•°æ®é›†è·¯å¾„
    
    # æ£€æŸ¥è´Ÿæ ·æœ¬ç›®å½•æ˜¯å¦å­˜åœ¨
    negative_dir = os.path.join(data_dir, 'negative')
    if not os.path.exists(negative_dir):
        print(f"è­¦å‘Š: è´Ÿæ ·æœ¬ç›®å½• {negative_dir} ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿æœ‰è´Ÿæ ·æœ¬æ•°æ®")
    
    dataset = DigitDataset(data_dir, transform=transform)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    # åŠ è½½é¢„è®­ç»ƒçš„ResNetæ¨¡å‹ï¼Œè¾“å‡ºå±‚æ”¹ä¸º6ç±»ï¼ˆ5ä¸ªæ•°å­—+1ä¸ªè´Ÿæ ·æœ¬ï¼‰
    model = models.resnet18(pretrained=True)
    model.fc = nn.Linear(model.fc.in_features, 6)  # 6ä¸ªç±»åˆ«ï¼ˆ5ä¸ªæ•°å­—+è´Ÿæ ·æœ¬ï¼‰
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # è®­ç»ƒå¾ªç¯
    num_epochs = 50
    best_accuracy = 0
    
    # ä½¿ç”¨tqdmåŒ…è£…epochå¾ªç¯
    epoch_pbar = tqdm(range(num_epochs), desc="æ€»è®­ç»ƒè¿›åº¦", position=0, ncols=100)
    
    for epoch in epoch_pbar:
        model.train()
        running_loss = 0.0
        
        # è®­ç»ƒé˜¶æ®µ
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [è®­ç»ƒ]', 
                         leave=False, ncols=100, position=1)
        
        for images, labels in train_pbar:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})
        
        avg_loss = running_loss / len(train_loader)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_predictions = []
        val_labels = []
        
        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [éªŒè¯]', 
                       leave=False, ncols=100, position=1)
        
        with torch.no_grad():
            for images, labels in val_pbar:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs, 1)
                
                val_predictions.extend(predicted.cpu().numpy())
                val_labels.extend(labels.cpu().numpy())
        
        accuracy = accuracy_score(val_labels, val_predictions)
        
        # æ›´æ–°æ€»è¿›åº¦æ¡
        epoch_pbar.set_postfix({
            'å¹³å‡æŸå¤±': f'{avg_loss:.4f}',
            'å‡†ç¡®ç‡': f'{accuracy:.4f}',
            'æœ€ä½³å‡†ç¡®ç‡': f'{best_accuracy:.4f}'
        })
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            torch.save(model.state_dict(), 'best_resnet_model_with_negative.pth')
            print(f'âœ¨ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜! å‡†ç¡®ç‡: {accuracy:.4f}')
    
    print(f'è®­ç»ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}')
    print('æ¨¡å‹ç°åœ¨å¯ä»¥è¯†åˆ«: 1, 2, 3, 4, 5 å’Œ è´Ÿæ ·æœ¬(éæ•°å­—)')

if __name__ == '__main__':
    train_model()